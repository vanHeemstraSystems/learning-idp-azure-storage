# Learning IDP: Azure Storage

This repository focuses on mastering Azure storage services using Python and Azure SDK to build, manage, and automate storage infrastructure for Internal Development Platform (IDP) development.

- [References](./REFERENCES.md)

## üéØ Learning Objectives

By working through this repository, you will:

1. Master Azure Storage Account management and configuration
1. Implement Blob storage operations and lifecycle management
1. Work with Azure Files and File Shares
1. Understand Azure Queue and Table storage patterns
1. Implement Data Lake Storage Gen2 for analytics
1. Configure storage security and access control
1. Optimize storage performance and costs

## üìö Prerequisites

- Python 3.11 or higher
- Azure subscription with contributor access
- Azure CLI installed and configured
- Completed [learning-idp-python-azure-sdk](https://github.com/vanHeemstraSystems/learning-idp-python-azure-sdk)
- Basic understanding of storage concepts
- Git and GitHub account

## üóÇÔ∏è Directory Structure

```
learning-idp-azure-storage/
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ REFERENCES.md                      # Links to resources and related repos
‚îú‚îÄ‚îÄ pyproject.toml                     # Python project configuration
‚îú‚îÄ‚îÄ requirements.txt                   # Python dependencies
‚îú‚îÄ‚îÄ requirements-dev.txt               # Development dependencies
‚îú‚îÄ‚îÄ .python-version                    # Python version for pyenv
‚îú‚îÄ‚îÄ .gitignore                         # Git ignore patterns
‚îú‚îÄ‚îÄ .env.example                       # Environment variables template
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ concepts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01-storage-overview.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02-storage-account-types.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03-blob-storage.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04-file-storage.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05-queue-table-storage.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 06-data-lake-gen2.md
‚îÇ   ‚îú‚îÄ‚îÄ guides/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ getting-started.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage-account-management.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blob-operations.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file-share-setup.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security-configuration.md
‚îÇ   ‚îî‚îÄ‚îÄ examples/
‚îÇ       ‚îú‚îÄ‚îÄ simple-storage-account.md
‚îÇ       ‚îú‚îÄ‚îÄ blob-lifecycle.md
‚îÇ       ‚îú‚îÄ‚îÄ file-share-access.md
‚îÇ       ‚îú‚îÄ‚îÄ queue-messaging.md
‚îÇ       ‚îî‚îÄ‚îÄ data-lake-analytics.md
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ authentication.py          # Azure authentication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py              # Custom exceptions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py          # Logging setup
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ storage_accounts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ account_manager.py         # Storage account CRUD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ account_types.py           # Account type utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ replication.py             # Replication configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ access_keys.py             # Key management
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ blob_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blob_client.py             # Blob operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ container_manager.py       # Container management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blob_upload.py             # Upload operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blob_download.py           # Download operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ blob_metadata.py           # Metadata management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lifecycle_manager.py       # Lifecycle policies
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ file_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_share_manager.py      # File share operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_client.py             # File operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ directory_manager.py       # Directory management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ share_snapshots.py         # Share snapshots
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ queue_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queue_manager.py           # Queue operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ message_handler.py         # Message operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queue_patterns.py          # Queue patterns
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ table_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table_manager.py           # Table operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_manager.py          # Entity CRUD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query_builder.py           # Query operations
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data_lake/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filesystem_manager.py      # Filesystem operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ directory_client.py        # Directory operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_client.py             # File operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ acl_manager.py             # ACL management
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sas_token.py               # SAS token generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rbac_manager.py            # RBAC configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encryption.py              # Encryption settings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ network_rules.py           # Network configuration
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ diagnostics.py             # Diagnostic settings
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py                 # Storage metrics
‚îÇ       ‚îî‚îÄ‚îÄ analytics.py               # Storage analytics
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ 01_storage_accounts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_storage_account.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_list_storage_accounts.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_configure_replication.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_manage_access_keys.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_account_properties.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 02_blob_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_container.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_upload_blob.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_download_blob.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_list_blobs.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05_blob_metadata.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 06_blob_snapshots.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 07_lifecycle_management.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 08_blob_versioning.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 03_file_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_file_share.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_upload_file.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_download_file.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_directory_operations.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05_share_snapshots.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 06_file_share_access.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 04_queue_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_queue.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_send_message.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_receive_message.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_peek_messages.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_queue_patterns.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 05_table_storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_table.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_insert_entity.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_query_entities.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_update_entity.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_batch_operations.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 06_data_lake/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_create_filesystem.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_directory_operations.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_file_operations.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_acl_management.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_data_analytics.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 07_security/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_generate_sas_token.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_configure_rbac.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_encryption_setup.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_network_rules.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 05_private_endpoints.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ 08_advanced/
‚îÇ       ‚îú‚îÄ‚îÄ 01_async_operations.py
‚îÇ       ‚îú‚îÄ‚îÄ 02_large_file_upload.py
‚îÇ       ‚îú‚îÄ‚îÄ 03_geo_replication.py
‚îÇ       ‚îú‚îÄ‚îÄ 04_cdn_integration.py
‚îÇ       ‚îî‚îÄ‚îÄ 05_backup_strategies.py
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ storage_accounts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basic_storage.json        # Basic storage account
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ premium_storage.json      # Premium storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_lake_gen2.json       # Data Lake Gen2
‚îÇ   ‚îú‚îÄ‚îÄ policies/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lifecycle_policy.json     # Lifecycle management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ access_policy.json        # Access policies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retention_policy.json     # Retention policies
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ backup_blob.sh            # Blob backup script
‚îÇ       ‚îú‚îÄ‚îÄ sync_files.sh             # File sync script
‚îÇ       ‚îî‚îÄ‚îÄ cleanup_old_data.py       # Data cleanup
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_storage_basics.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_blob_operations.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_file_share_management.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_data_lake_analytics.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_storage_optimization.ipynb
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_storage_environment.sh   # Setup script
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_resources.sh           # Cleanup script
‚îÇ   ‚îú‚îÄ‚îÄ storage_audit.py               # Storage audit tool
‚îÇ   ‚îî‚îÄ‚îÄ cost_analysis.py               # Cost analysis tool
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_account_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_blob_client.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_file_share_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_queue_manager.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_table_manager.py
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ       ‚îú‚îÄ‚îÄ test_storage_account_lifecycle.py
‚îÇ       ‚îú‚îÄ‚îÄ test_blob_operations.py
‚îÇ       ‚îú‚îÄ‚îÄ test_file_operations.py
‚îÇ       ‚îî‚îÄ‚îÄ test_data_lake_operations.py
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îú‚îÄ‚îÄ test.yml                   # Run tests
        ‚îú‚îÄ‚îÄ examples.yml               # Test examples
        ‚îî‚îÄ‚îÄ cleanup.yml                # Cleanup resources
```

## üöÄ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/vanHeemstraSystems/learning-idp-azure-storage.git
cd learning-idp-azure-storage
```

### 2. Set Up Python Environment

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# On Linux/MacOS:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### 3. Configure Azure Authentication

```bash
# Login to Azure
az login

# Set subscription
az account set --subscription "your-subscription-id"

# Create service principal (optional)
az ad sp create-for-rbac --name "idp-storage-sp" --role "Storage Blob Data Contributor"

# Configure environment variables
cp .env.example .env
# Edit .env with your credentials
```

### 4. Run Your First Example

```bash
# Create a storage account
python examples/01_storage_accounts/01_create_storage_account.py

# Create a blob container and upload a file
python examples/02_blob_storage/01_create_container.py
python examples/02_blob_storage/02_upload_blob.py

# Create a file share
python examples/03_file_storage/01_create_file_share.py
```

## üìñ Learning Path

Follow this recommended sequence:

### Week 1: Storage Fundamentals

**Day 1-2: Understanding Azure Storage**

1. Read `docs/concepts/01-storage-overview.md`
1. Study `docs/concepts/02-storage-account-types.md`
1. Run `examples/01_storage_accounts/01_create_storage_account.py`

**Day 3-5: Blob Storage**

1. Read `docs/concepts/03-blob-storage.md`
1. Complete all examples in `examples/02_blob_storage/`
1. Practice upload, download, and metadata operations

**Day 6-7: Blob Lifecycle Management**

1. Study lifecycle policies
1. Implement tiering strategies
1. Configure versioning and snapshots

### Week 2: File & Queue Storage

**Day 1-3: Azure Files**

1. Read `docs/concepts/04-file-storage.md`
1. Work through `examples/03_file_storage/`
1. Configure file shares and SMB access

**Day 4-5: Queue Storage**

1. Complete examples in `examples/04_queue_storage/`
1. Implement message patterns
1. Practice queue-based architectures

**Day 6-7: Table Storage**

1. Study NoSQL patterns
1. Work through `examples/05_table_storage/`
1. Implement entity operations

### Week 3: Data Lake & Security

**Day 1-3: Data Lake Gen2**

1. Read `docs/concepts/06-data-lake-gen2.md`
1. Complete `examples/06_data_lake/`
1. Configure hierarchical namespace
1. Implement ACL management

**Day 4-7: Storage Security**

1. Read `docs/guides/security-configuration.md`
1. Complete all examples in `examples/07_security/`
1. Configure SAS tokens and RBAC
1. Implement encryption and network rules

### Week 4: Advanced Topics & Production

**Day 1-3: Advanced Operations**

1. Work through `examples/08_advanced/`
1. Implement async operations
1. Configure geo-replication

**Day 4-5: Performance Optimization**

1. Study performance best practices
1. Implement caching strategies
1. Configure CDN integration

**Day 6-7: Production Readiness**

1. Implement monitoring and alerting
1. Configure backup strategies
1. Optimize costs

## üîë Key Azure SDK Packages

### Storage Management & Data Plane

```python
# Management (Control Plane)
azure-mgmt-storage>=21.0.0          # Storage account management

# Data Plane - Blob Storage
azure-storage-blob>=12.19.0         # Blob operations
azure-storage-blob-changefeed>=12.0.0  # Change feed

# Data Plane - File Storage
azure-storage-file-share>=12.15.0   # File share operations
azure-storage-file-datalake>=12.14.0  # Data Lake Gen2

# Data Plane - Queue Storage
azure-storage-queue>=12.9.0         # Queue operations

# Supporting Libraries
azure-identity>=1.15.0              # Authentication
azure-core>=1.29.0                  # Core functionality
```

## üí° Common Operations Examples

### Create Storage Account

```python
from azure.identity import DefaultAzureCredential
from azure.mgmt.storage import StorageManagementClient
from azure.mgmt.storage.models import (
    StorageAccountCreateParameters,
    Sku,
    SkuName,
    Kind
)

credential = DefaultAzureCredential()
storage_client = StorageManagementClient(credential, subscription_id)

# Create storage account
storage_params = StorageAccountCreateParameters(
    sku=Sku(name=SkuName.STANDARD_LRS),
    kind=Kind.STORAGE_V2,
    location='westeurope',
    tags={
        'environment': 'development',
        'project': 'idp-learning'
    },
    enable_https_traffic_only=True,
    minimum_tls_version='TLS1_2',
    allow_blob_public_access=False
)

storage_account = storage_client.storage_accounts.begin_create(
    'my-rg',
    'mystorageaccount',
    storage_params
).result()

print(f"Created storage account: {storage_account.name}")
print(f"Primary endpoint: {storage_account.primary_endpoints.blob}")
```

### Upload and Download Blobs

```python
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient

# Initialize clients
credential = DefaultAzureCredential()
account_url = "https://mystorageaccount.blob.core.windows.net"
blob_service_client = BlobServiceClient(account_url, credential=credential)

# Create container
container_name = "my-container"
container_client = blob_service_client.create_container(container_name)
print(f"Created container: {container_name}")

# Upload blob
blob_name = "sample.txt"
blob_client = blob_service_client.get_blob_client(
    container=container_name,
    blob=blob_name
)

with open("local-file.txt", "rb") as data:
    blob_client.upload_blob(data, overwrite=True)
    print(f"Uploaded blob: {blob_name}")

# Download blob
with open("downloaded-file.txt", "wb") as download_file:
    download_file.write(blob_client.download_blob().readall())
    print(f"Downloaded blob: {blob_name}")

# Set blob metadata
metadata = {
    'author': 'Willem',
    'category': 'documentation'
}
blob_client.set_blob_metadata(metadata)

# Get blob properties
properties = blob_client.get_blob_properties()
print(f"Content type: {properties.content_settings.content_type}")
print(f"Metadata: {properties.metadata}")
```

### Implement Lifecycle Management

```python
from azure.identity import DefaultAzureCredential
from azure.mgmt.storage import StorageManagementClient
from azure.mgmt.storage.models import (
    ManagementPolicy,
    ManagementPolicySchema,
    ManagementPolicyRule,
    ManagementPolicyDefinition,
    ManagementPolicyAction,
    ManagementPolicyBaseBlob,
    ManagementPolicySnapShot,
    DateAfterModification
)

credential = DefaultAzureCredential()
storage_client = StorageManagementClient(credential, subscription_id)

# Define lifecycle policy
policy = ManagementPolicy(
    policy=ManagementPolicySchema(
        rules=[
            ManagementPolicyRule(
                enabled=True,
                name='move-to-cool',
                type='Lifecycle',
                definition=ManagementPolicyDefinition(
                    actions=ManagementPolicyAction(
                        base_blob=ManagementPolicyBaseBlob(
                            tier_to_cool=DateAfterModification(
                                days_after_modification_greater_than=30
                            ),
                            tier_to_archive=DateAfterModification(
                                days_after_modification_greater_than=90
                            ),
                            delete=DateAfterModification(
                                days_after_modification_greater_than=365
                            )
                        ),
                        snapshot=ManagementPolicySnapShot(
                            delete=DateAfterModification(
                                days_after_creation_greater_than=90
                            )
                        )
                    ),
                    filters={
                        'blobTypes': ['blockBlob'],
                        'prefixMatch': ['logs/']
                    }
                )
            )
        ]
    )
)

# Apply lifecycle policy
storage_client.management_policies.create_or_update(
    'my-rg',
    'mystorageaccount',
    'default',
    policy
)
print("Lifecycle policy applied")
```

### Create and Use File Share

```python
from azure.identity import DefaultAzureCredential
from azure.storage.fileshare import ShareServiceClient, ShareClient, ShareFileClient

# Initialize clients
credential = DefaultAzureCredential()
account_url = "https://mystorageaccount.file.core.windows.net"
share_service_client = ShareServiceClient(account_url, credential=credential)

# Create file share
share_name = "my-share"
share_client = share_service_client.create_share(share_name, quota=100)
print(f"Created file share: {share_name}")

# Create directory
directory_name = "my-directory"
directory_client = share_client.get_directory_client(directory_name)
directory_client.create_directory()
print(f"Created directory: {directory_name}")

# Upload file
file_name = "sample.txt"
file_client = share_client.get_file_client(f"{directory_name}/{file_name}")

with open("local-file.txt", "rb") as source_file:
    file_client.upload_file(source_file)
    print(f"Uploaded file: {file_name}")

# Download file
with open("downloaded-file.txt", "wb") as file_handle:
    data = file_client.download_file()
    data.readinto(file_handle)
    print(f"Downloaded file: {file_name}")

# Create share snapshot
snapshot = share_client.create_snapshot()
print(f"Created snapshot: {snapshot['snapshot']}")
```

### Work with Queue Storage

```python
from azure.identity import DefaultAzureCredential
from azure.storage.queue import QueueServiceClient, QueueClient
import json

# Initialize clients
credential = DefaultAzureCredential()
account_url = "https://mystorageaccount.queue.core.windows.net"
queue_service_client = QueueServiceClient(account_url, credential=credential)

# Create queue
queue_name = "my-queue"
queue_client = queue_service_client.create_queue(queue_name)
print(f"Created queue: {queue_name}")

# Send message
message_data = {
    'task': 'process_data',
    'file': 'data.csv',
    'priority': 'high'
}
message = json.dumps(message_data)
queue_client.send_message(message)
print(f"Sent message: {message}")

# Receive messages
messages = queue_client.receive_messages(messages_per_page=5)
for msg in messages:
    print(f"Received message: {msg.content}")
    
    # Process message
    data = json.loads(msg.content)
    print(f"Processing task: {data['task']}")
    
    # Delete message after processing
    queue_client.delete_message(msg.id, msg.pop_receipt)
    print(f"Deleted message: {msg.id}")

# Peek at messages without removing them
peeked_messages = queue_client.peek_messages(max_messages=5)
for msg in peeked_messages:
    print(f"Peeked message: {msg.content}")
```

### Data Lake Gen2 Operations

```python
from azure.identity import DefaultAzureCredential
from azure.storage.filedatalake import (
    DataLakeServiceClient,
    FileSystemClient,
    DataLakeDirectoryClient
)

# Initialize clients
credential = DefaultAzureCredential()
account_url = "https://mystorageaccount.dfs.core.windows.net"
service_client = DataLakeServiceClient(account_url, credential=credential)

# Create file system
file_system_name = "my-filesystem"
file_system_client = service_client.create_file_system(file_system_name)
print(f"Created file system: {file_system_name}")

# Create directory
directory_name = "data/raw"
directory_client = file_system_client.create_directory(directory_name)
print(f"Created directory: {directory_name}")

# Upload file
file_name = "dataset.csv"
file_client = directory_client.create_file(file_name)

with open("local-dataset.csv", "rb") as data:
    file_contents = data.read()
    file_client.upload_data(file_contents, overwrite=True)
    print(f"Uploaded file: {file_name}")

# Set ACL (Access Control List)
acl = "user::rwx,group::r--,other::---"
directory_client.set_access_control(acl=acl)
print(f"Set ACL: {acl}")

# List files in directory
paths = file_system_client.get_paths(path=directory_name)
for path in paths:
    print(f"Path: {path.name}")
```

## üéØ Best Practices

### 1. Storage Account Configuration

```python
# Use appropriate redundancy
storage_params = StorageAccountCreateParameters(
    sku=Sku(name=SkuName.STANDARD_GRS),  # Geo-redundant for production
    kind=Kind.STORAGE_V2,
    enable_https_traffic_only=True,
    minimum_tls_version='TLS1_2',
    allow_blob_public_access=False,  # Security best practice
    is_hns_enabled=True  # Enable hierarchical namespace for Data Lake Gen2
)
```

### 2. Secure Access with SAS Tokens

```python
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions
from datetime import datetime, timedelta

# Generate SAS token with limited permissions and expiry
sas_token = generate_blob_sas(
    account_name='mystorageaccount',
    container_name='my-container',
    blob_name='sensitive-data.txt',
    account_key=account_key,
    permission=BlobSasPermissions(read=True),
    expiry=datetime.utcnow() + timedelta(hours=1)
)

# Use SAS token
blob_url = f"https://mystorageaccount.blob.core.windows.net/my-container/sensitive-data.txt?{sas_token}"
```

### 3. Implement Retry Logic

```python
from azure.core.pipeline.policies import RetryPolicy
from azure.storage.blob import BlobServiceClient

# Configure retry policy
retry_policy = RetryPolicy(
    retry_total=3,
    retry_backoff_factor=2,
    retry_backoff_max=30
)

blob_service_client = BlobServiceClient(
    account_url,
    credential=credential,
    retry_policy=retry_policy
)
```

### 4. Use Async Operations for Better Performance

```python
from azure.storage.blob.aio import BlobServiceClient
import asyncio

async def upload_multiple_blobs():
    async with BlobServiceClient(account_url, credential=credential) as client:
        container_client = client.get_container_client("my-container")
        
        tasks = []
        for i in range(10):
            blob_client = container_client.get_blob_client(f"file-{i}.txt")
            task = blob_client.upload_blob(f"Data {i}", overwrite=True)
            tasks.append(task)
        
        await asyncio.gather(*tasks)

asyncio.run(upload_multiple_blobs())
```

## üîß Development Tools

### Essential Tools

```bash
# Install storage tools
pip install azure-storage-blob
pip install azure-storage-file-share
pip install azure-storage-queue

# Storage Explorer (GUI)
# Download from: https://azure.microsoft.com/en-us/products/storage/storage-explorer/

# Code quality
black src/ examples/
ruff check src/ examples/
mypy src/

# Testing
pytest tests/
```

### Storage Testing

```bash
# Use Azurite for local testing
npm install -g azurite

# Start Azurite
azurite --silent --location /tmp/azurite --debug /tmp/azurite-debug.log

# Connect to Azurite in Python
from azure.storage.blob import BlobServiceClient

# Azurite default connection string
connection_string = "DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;"

blob_service_client = BlobServiceClient.from_connection_string(connection_string)
```

## üìä Storage Architecture Patterns

### Tiered Storage Strategy

```
Hot Tier (Frequent Access)
    ‚Üì After 30 days
Cool Tier (Infrequent Access)
    ‚Üì After 90 days
Archive Tier (Rare Access)
    ‚Üì After 365 days
Delete
```

### Data Lake Organization

```
/raw/                   # Raw ingested data
  /source1/
  /source2/
/processed/            # Cleaned and transformed
  /daily/
  /monthly/
/curated/              # Business-ready data
  /reports/
  /analytics/
```

## üîó Related Repositories

- [learning-internal-development-platform](https://github.com/vanHeemstraSystems/learning-internal-development-platform) - Main overview
- [learning-idp-python-azure-sdk](https://github.com/vanHeemstraSystems/learning-idp-python-azure-sdk) - Azure SDK fundamentals
- [learning-idp-azure-compute](https://github.com/vanHeemstraSystems/learning-idp-azure-compute) - Compute resources
- [learning-idp-azure-networking](https://github.com/vanHeemstraSystems/learning-idp-azure-networking) - Network configuration
- [learning-idp-azure-security](https://github.com/vanHeemstraSystems/learning-idp-azure-security) - Security configuration

## ü§ù Contributing

This is a personal learning repository, but suggestions and improvements are welcome!

1. Fork the repository
1. Create a feature branch
1. Make your changes with tests
1. Ensure all tests pass
1. Submit a pull request

## üìÑ License

This project is for educational purposes. See LICENSE file for details.

## üìß Contact

Willem van Heemstra

- GitHub: [@vanHeemstraSystems](https://github.com/vanHeemstraSystems)
- LinkedIn: [Willem van Heemstra](https://www.linkedin.com/in/willemvanheemstra/)

-----

*Last updated: December 18, 2025*
*Part of the learning-internal-development-platform series*
